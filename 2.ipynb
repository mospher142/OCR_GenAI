{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import fitz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pdffile = \"extract/24000005.pdf\"\n",
    "doc = fitz.open(pdffile)\n",
    "print(doc.page_count)\n",
    "zoom = 6\n",
    "mat = fitz.Matrix(zoom, zoom)\n",
    "count = 0\n",
    "# Count variable is to get the number of pages in the pdf\n",
    "for p in doc:\n",
    "    count += 1\n",
    "for i in range(count):\n",
    "    val = f\"image_{i+1}.png\"\n",
    "    page = doc.load_page(i)\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    pix.save(val)\n",
    "\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"image_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#thresh, im_bw = cv2.threshold(img, 210, 300, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "## Min-Max Normalization\n",
    "# If you need it in [0, 255] range for an 8-bit image\n",
    "normalized_img_255 = cv2.normalize(img, None, alpha=1, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "## Z-Score Normalization (Standardization)\n",
    "# Calculate the mean and standard deviation\n",
    "mean, std_dev = cv2.meanStdDev(img)\n",
    "z_score_normalized_img = (img - mean[0][0]) / std_dev[0][0]\n",
    "z_score_normalized_img_255 = cv2.normalize(z_score_normalized_img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "## Apply Histogram Equalization\n",
    "equalized_img = cv2.equalizeHist(img)\n",
    "\n",
    "## CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(100, 10))\n",
    "clahe_img = clahe.apply(img)\n",
    "\n",
    "cv2.imwrite(\"processed_image.png\", clahe_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"image_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define target and assumed initial PPI\n",
    "target_ppi = 300\n",
    "initial_ppi = 150  # Adjust this if you know the initial PPI (e.g., 72, 96, or 150 PPI)\n",
    "\n",
    "# Calculate scaling factor to achieve 300 PPI or higher\n",
    "scaling_factor = target_ppi / initial_ppi\n",
    "\n",
    "# Calculate new dimensions based on the scaling factor\n",
    "new_width = int(img.shape[1] * scaling_factor)\n",
    "new_height = int(img.shape[0] * scaling_factor)\n",
    "new_size = (new_width, new_height)\n",
    "\n",
    "# Resize the image with high-quality interpolation (Cubic interpolation)\n",
    "upscaled_img = cv2.resize(clahe_img, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "# Save the upscaled image\n",
    "cv2.imwrite(\"processed_image.png\", upscaled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(\"image_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Step 1: Apply Median Blur to remove salt-and-pepper noise\n",
    "denoised_img = cv2.medianBlur(upscaled_img, 3)  # Use a small kernel size to avoid blurring text\n",
    "\n",
    "# Step 2: Apply Gaussian Blur for additional smoothing\n",
    "denoised_img_g = cv2.GaussianBlur(denoised_img, (5, 5), 4)\n",
    "\n",
    "# Optional Step: Apply Bilateral Filter if edges need more preservation\n",
    "denoised_img_s = cv2.bilateralFilter(denoised_img_g, 10, 75, 75)\n",
    "\n",
    "cv2.imwrite(\"processed_image.png\", denoised_img_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinning and Skeletonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"image_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "\n",
    "erosion = cv2.erode(img, kernel, iterations = 1)\n",
    "dilation = cv2.dilate(img, kernel, iterations = 1) # opposite of erosion\n",
    "opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"processed_image.png\", erosion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding and Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"image_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "denoised_img = cv2.medianBlur(img, 3)  # Kernel size can be adjusted\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "enhanced_img = clahe.apply(denoised_img)\n",
    "binary_img = cv2.adaptiveThreshold(\n",
    "    enhanced_img, \n",
    "    255, \n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, \n",
    "    19, \n",
    "    1\n",
    ")\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "dilated_img = cv2.dilate(binary_img, kernel, iterations=1)\n",
    "thresh, im_bw = cv2.threshold(dilated_img, 240, 210, cv2.THRESH_BINARY)\n",
    "cv2.imwrite(\"processed_image.png\", im_bw)  # Or use `deskewed_img` if dilation is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image using cv2\n",
    "image = cv2.imread(\"image_1.png\")\n",
    "\n",
    "# Example preprocessing: convert to grayscale and apply GaussianBlur\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Normalization\n",
    "clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(100, 10))\n",
    "clahe_img = clahe.apply(gray_img)\n",
    "\n",
    "# Removing Noise\n",
    "denoised_img = cv2.GaussianBlur(clahe_img, (5, 5), 0)\n",
    "\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "erosion = cv2.erode(denoised_img, kernel, iterations = 1)\n",
    "\n",
    "thresh, im_bw = cv2.threshold(erosion, 220, 300, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imwrite(\"processed_image.png\", im_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with merged bounding boxes saved as output_with_bounding_boxes_easyocr.png\n"
     ]
    }
   ],
   "source": [
    "# Initialize the EasyOCR reader with the desired language\n",
    "reader = easyocr.Reader(['fr'])  # Specify language\n",
    "\n",
    "# Load the image\n",
    "image_file = \"processed_image.png\"\n",
    "img = cv2.imread(image_file)\n",
    "\n",
    "# Detect text using EasyOCR\n",
    "results = reader.readtext(img)\n",
    "\n",
    "# Initialize a list to store the coordinates of horizontal bounding boxes\n",
    "horizontal_boxes = []\n",
    "\n",
    "# Collect bounding boxes that are horizontal\n",
    "for (bbox, text, confidence) in results:\n",
    "    if confidence > 0.3:  # Confidence threshold\n",
    "        # bbox contains the coordinates of the box around the text\n",
    "        (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "        top_left = tuple(map(int, top_left))\n",
    "        bottom_right = tuple(map(int, bottom_right))\n",
    "\n",
    "        # Calculate width and height\n",
    "        width = bottom_right[0] - top_left[0]\n",
    "        height = bottom_right[1] - top_left[1]\n",
    "        \n",
    "        # Only process horizontal bounding boxes\n",
    "        if width > height:\n",
    "            horizontal_boxes.append((top_left[0], top_left[1], bottom_right[0], bottom_right[1]))  # Store as (x1, y1, x2, y2)\n",
    "\n",
    "# Sort boxes by their y-coordinate (top of the bounding box) for line-based grouping\n",
    "horizontal_boxes.sort(key=lambda box: box[1])\n",
    "\n",
    "# Merge bounding boxes on the same line\n",
    "merged_boxes = []\n",
    "current_line_boxes = []\n",
    "\n",
    "# Define a threshold for merging boxes on the same line\n",
    "y_threshold = 10  # Adjust based on spacing between lines in the image\n",
    "x_gap_threshold = 20  # Adjust based on spacing between words\n",
    "\n",
    "for box in horizontal_boxes:\n",
    "    if not current_line_boxes:\n",
    "        current_line_boxes.append(box)\n",
    "        continue\n",
    "\n",
    "    _, y1, _, y2 = box\n",
    "    _, prev_y1, _, prev_y2 = current_line_boxes[-1]\n",
    "\n",
    "    # Check if the box is on the same line as the previous one\n",
    "    if abs(y1 - prev_y1) <= y_threshold or abs(y2 - prev_y2) <= y_threshold:\n",
    "        current_line_boxes.append(box)\n",
    "    else:\n",
    "        # Merge all boxes in the current line group\n",
    "        min_x1 = min(b[0] for b in current_line_boxes)\n",
    "        min_y1 = min(b[1] for b in current_line_boxes)\n",
    "        max_x2 = max(b[2] for b in current_line_boxes)\n",
    "        max_y2 = max(b[3] for b in current_line_boxes)\n",
    "        merged_boxes.append((min_x1, min_y1, max_x2 - min_x1, max_y2 - min_y1))  # Store as (x, y, w, h)\n",
    "        current_line_boxes = [box]\n",
    "\n",
    "# Merge any remaining boxes in the last line\n",
    "if current_line_boxes:\n",
    "    min_x1 = min(b[0] for b in current_line_boxes)\n",
    "    min_y1 = min(b[1] for b in current_line_boxes)\n",
    "    max_x2 = max(b[2] for b in current_line_boxes)\n",
    "    max_y2 = max(b[3] for b in current_line_boxes)\n",
    "    merged_boxes.append((min_x1, min_y1, max_x2 - min_x1, max_y2 - min_y1))\n",
    "\n",
    "# Save the initial image with merged bounding boxes\n",
    "for (x, y, w, h) in merged_boxes:\n",
    "    img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green box\n",
    "\n",
    "output_image_path = \"output_with_bounding_boxes_easyocr.png\"\n",
    "cv2.imwrite(output_image_path, img)\n",
    "print(\"Image with merged bounding boxes saved as\", output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bounding box 1:\n",
      "Detected Text: Cople à publler aux annexes au Rionideur belge | Confidence: 0.3260280522122447\n",
      "Results for bounding box 2:\n",
      "Results for bounding box 3:\n",
      "Detected Text: bcloo | Confidence: 0.7762932974180531\n",
      "Results for bounding box 4:\n",
      "Detected Text: 24000005* | Confidence: 0.9953947650202262\n",
      "Detected Text: au | Confidence: 0.999609236786169\n",
      "Detected Text: du tribuîffâl dë Y'entreprise | Confidence: 0.24719620795899053\n",
      "Detected Text: greffe | Confidence: 0.9958295211606153\n",
      "Results for bounding box 5:\n",
      "Detected Text: 361986926 | Confidence: 0.36588501912038923\n",
      "Results for bounding box 6:\n",
      "Detected Text: (on entler) : | Confidence: 0.673627987758791\n",
      "Detected Text: GRANDR | Confidence: 0.9742132245710441\n",
      "Results for bounding box 7:\n",
      "Detected Text: (en abrégs) | Confidence: 0.5598454815176684\n",
      "Results for bounding box 8:\n",
      "Detected Text: Forme légale : | Confidence: 0.7556094759473633\n",
      "Detected Text: SRL | Confidence: 0.8677277938076173\n",
      "Results for bounding box 9:\n",
      "Detected Text: Adresse complole du siege : | Confidence: 0.540150001870057\n",
      "Detected Text: 209 Boulevard Lambermont; Bolte 12, 1030 Schaerbook | Confidence: 0.5924359494973368\n",
      "Results for bounding box 10:\n",
      "Detected Text: MODIFICATION SIEGE SOCIAL | Confidence: 0.7201230851039968\n",
      "Results for bounding box 11:\n",
      "Detected Text: GRANDR | Confidence: 0.8855929852180331\n",
      "Detected Text: 0 | Confidence: 0.668411886073855\n",
      "Detected Text: ayant 8on slBge sodal à 1030 Schaorbeek; Boulevard | Confidence: 0.3254022048634797\n",
      "Results for bounding box 12:\n",
      "Detected Text: Lambenont 2096012 qu0: | Confidence: 0.9161503655407214\n",
      "Results for bounding box 13:\n",
      "Detected Text: Promlera régdluton | Confidence: 0.21883544173431654\n",
      "Results for bounding box 14:\n",
      "Detected Text: ci9ge | Confidence: 0.0894211608408912\n",
      "Results for bounding box 15:\n",
      "Detected Text: du | Confidence: 0.9987777916820436\n",
      "Results for bounding box 16:\n",
      "Detected Text: 1084 ielles. | Confidence: 0.1609129472355962\n",
      "Results for bounding box 17:\n",
      "Detected Text: Deuxiàme résoluton | Confidence: 0.4737823917491988\n",
      "Detected Text: 0 | Confidence: 0.2497014401186215\n",
      "Detected Text: Approbatlon de la modlcation présentée | Confidence: 0.560861925026695\n",
      "Results for bounding box 18:\n",
      "Detected Text: @t confne l changement | Confidence: 0.7269257538441416\n",
      "Results for bounding box 19:\n",
      "Detected Text: Coordlnatlon 0t publilcatlon | Confidence: 0.5087500919688679\n",
      "Results for bounding box 20:\n",
      "Detected Text: dit cavant | Confidence: 0.8187916639761216\n",
      "Results for bounding box 21:\n",
      "Detected Text: Lassemblée générale extraordlnalre donne lous pouvoira à Yadminstratour pour faire le nécéssalrequant | Confidence: 0.37914333711892545\n",
      "Results for bounding box 22:\n",
      "Detected Text: POUR BXTRAT ANALYTIQUE | Confidence: 0.46883344525078957\n",
      "Results for bounding box 23:\n",
      "Detected Text: Toutos CoS résolutions gont prises à l'unanimilé  | Confidence: 0.17841237629584897\n",
      "Results for bounding box 24:\n",
      "Detected Text: Gerant | Confidence: 0.9955263715280963\n",
      "Detected Text: 2 | Confidence: 0.2952847794921496\n",
      "Detected Text: TiesOr MADODA TUYINAMA | Confidence: 0.4500693391863989\n",
      "Results for bounding box 25:\n",
      "Detected Text: extraordlnalre du 13 décembre 2023. | Confidence: 0.8430809008975866\n",
      "Results for bounding box 26:\n",
      "Detected Text: Ayrosfe | Confidence: 0.19319040085275868\n",
      "Detected Text: Nom 0t quallle du notaire Instrumentant ou d la porgonnoou doe pereonnos | Confidence: 0.31678756711468226\n",
      "Results for bounding box 27:\n",
      "Detected Text: Nom @t slgnature (pas applicable aux actog de type & Mantlon %) | Confidence: 0.2756115371090725\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the extracted text from each bounding box\n",
    "document = []\n",
    "\n",
    "# Perform OCR on each bounding box region\n",
    "for i, (x, y, w, h) in enumerate(merged_boxes):\n",
    "    # Crop each region of interest\n",
    "    roi = img[y:y + h, x:x + w]\n",
    "\n",
    "    # Perform OCR on the cropped region\n",
    "    result = reader.readtext(roi, detail=1)\n",
    "\n",
    "    # Extract text from OCR results and append to document\n",
    "    box_text = \" \".join([text for (_, text, confidence) in result if confidence > 0.3])\n",
    "    document.append(box_text)\n",
    "\n",
    "    # Print results for each bounding box (optional for debugging)\n",
    "    print(f\"Results for bounding box {i + 1}:\")\n",
    "    for (bbox, text, confidence) in result:\n",
    "        print(f\"Detected Text: {text} | Confidence: {confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cople à publler aux annexes au Rionideur belge',\n",
       " '',\n",
       " 'bcloo',\n",
       " '24000005* au greffe',\n",
       " '361986926',\n",
       " '(on entler) : GRANDR',\n",
       " '(en abrégs)',\n",
       " 'Forme légale : SRL',\n",
       " 'Adresse complole du siege : 209 Boulevard Lambermont; Bolte 12, 1030 Schaerbook',\n",
       " 'MODIFICATION SIEGE SOCIAL',\n",
       " 'GRANDR 0 ayant 8on slBge sodal à 1030 Schaorbeek; Boulevard',\n",
       " 'Lambenont 2096012 qu0:',\n",
       " '',\n",
       " '',\n",
       " 'du',\n",
       " '',\n",
       " 'Deuxiàme résoluton Approbatlon de la modlcation présentée',\n",
       " '@t confne l changement',\n",
       " 'Coordlnatlon 0t publilcatlon',\n",
       " 'dit cavant',\n",
       " 'Lassemblée générale extraordlnalre donne lous pouvoira à Yadminstratour pour faire le nécéssalrequant',\n",
       " 'POUR BXTRAT ANALYTIQUE',\n",
       " '',\n",
       " 'Gerant TiesOr MADODA TUYINAMA',\n",
       " 'extraordlnalre du 13 décembre 2023.',\n",
       " 'Nom 0t quallle du notaire Instrumentant ou d la porgonnoou doe pereonnos',\n",
       " '']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\LangChain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define the output schema\n",
    "class Document(BaseModel):\n",
    "    company_name: str = Field(description=\"Company Name\")\n",
    "    company_identifier: str = Field(description=\"Company Identifier Number\")\n",
    "    document_purpose: str = Field(description=\"Document Purpose\")\n",
    "    key_terms: str = Field(description=\"Key terms related with the document\")\n",
    "\n",
    "class Info(BaseModel):\n",
    "    infomration: List[Document]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Info)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant specialized in extracting key business details from documents. \"\n",
    "            \"Your goal is to identify and translate relevant information into English if necessary, then format the output \"\n",
    "            \"according to the specified JSON schema. Ensure that each extracted field is accurate, complete, and follows the schema precisely.\\n\\n\"\n",
    "            \"Please extract the following fields:\\n\\n\"\n",
    "            \"1. **Company Name**: The full name of the company as it appears in the document.\\n\"\n",
    "            \"2. **Company Identifier**: A unique identifier for the company, such as a registration or business number. Only extract the number.\\n\"\n",
    "            \"3. **Document Purpose**: The purpose or intent of the document (e.g., 'Appointment of Directors', 'Annual Report'). \"\n",
    "            \"Translate this to English if it’s in another language.\\n\"\n",
    "            \"4. **Key Terms about the Document Purpose**: Extract detailed information relevant to the document’s purpose, such as roles, positions, and effective dates. \"\n",
    "            \"For instance, if the document covers the appointment of directors, include terms like the position title and effective date. Translate these terms to English if needed.\\n\\n\"\n",
    "            \"{format_instructions}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{query}\"\n",
    "        ),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | model | parser\n",
    "result = chain.invoke({\"query\": document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infomration=[Document(company_name='GRANDR', company_identifier='361986926', document_purpose='Modification of Registered Office', key_terms='Legal form: SRL; Complete address of the registered office: 209 Boulevard Lambermont; Box 12, 1030 Schaerbeek; Extraordinary general assembly gives all powers to the administrator to carry out the necessary arrangements.')]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface  import HuggingFaceEndpoint\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    model_kwargs={\"return_dict\": True}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"], \n",
    "    template=\"\"\"\n",
    "    Please take the following text and organize it into well-structured sections with clear and relevant headings \\\n",
    "    and paragraphs in French. Make sure that:\n",
    "\n",
    "    - Extract what is the Qbjet_de Lacte.\n",
    "    \n",
    "    - Each section has an appropriate heading that reflects its content.\n",
    "    - All original content is preserved without omissions or modifications.\n",
    "    - The text is grouped into logically organized paragraphs under each heading.\n",
    "\n",
    "    Text to format:\n",
    "    {text}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "result = chain.invoke({\"text\": document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Document Officiel\n",
      "\n",
      "## Objet de l'Acte\n",
      "La société a pour objet, tant en Belgique qu'à l'étranger, pour son compte propre ou pour le compte de tiers, seul ou en association, les activités suivantes :\n",
      "\n",
      "- **Constructions**\n",
      "  - Génie civil : construction de routes, de voies ferrées, de ponts et de tunnels.\n",
      "  - Construction de réseaux et de lignes.\n",
      "  - Construction de réseaux pour fluides.\n",
      "  - Construction de réseaux électriques et de télécommunications.\n",
      "\n",
      "- **Travaux de construction spécialisés**\n",
      "  - Démolition ; préparation des sites ; forages d'essai et sondages.\n",
      "  - Travaux d'installation.\n",
      "  - Travaux d'isolation.\n",
      "  - Mise en œuvre dans des bâtiments ou d'autres projets de construction de matériaux d'isolation thermique, matériaux d'isolation acoustique et anti-vibratile.\n",
      "  - Travaux d'isolation de canalisations de chauffage ou de réfrigération, de chambres froides ou d'entrepôts frigorifiques.\n",
      "  - Travaux de finition.\n",
      "  - Travaux de plâtrerie : Application dans des bâtiments ou d'autres projets de construction de plâtre ou de stuc pour l'intérieur, y compris les matériaux de lattage associés.\n",
      "  - Montage de cloisons sèches à base de plâtre.\n",
      "  - Tous travaux de menuiserie.\n",
      "  - Travaux de revêtement des sols et des murs et des plafonds.\n",
      "  - Montage de menuiseries extérieures et intérieures : portes, fenêtres, escaliers, placards de cuisines équipées, équipements pour magasins, dormants de portes et fenêtres, etc.\n",
      "  - Montage de cloisons mobiles.\n",
      "  - Montage de portes de garage, de volets, de persiennes, de grillages, etc.\n",
      "\n",
      "## Informations Générales\n",
      "\n",
      "### Dénomination de la Société\n",
      "- **Nom complet :** THERMO SANITAR\n",
      "- **Nom abrégé :** SNC (Société en nom collectif)\n",
      "\n",
      "### Siège Social\n",
      "- **Adresse :** Avenue de Broqueville 250, Boîte 5, 1200 Woluwe-Saint-Lambert\n",
      "- **Région :** Bruxelles Capitale\n",
      "\n",
      "## Adoption de Nouveaux Statuts\n",
      "\n",
      "### Procès-Verbal de l'Assemblée Générale Extraordinaire\n",
      "Lors de l'assemblée générale extraordinaire du 15 décembre 2023, il a été décidé d'adopter et de refondre les statuts en conformité avec le Code des sociétés et des associations.\n",
      "\n",
      "### Forme Légale\n",
      "La société est une société en nom collectif.\n",
      "\n",
      "## Publication\n",
      "Le dépôt de l'acte a été effectué au greffe, et une copie est à publier aux annexes du Moniteur belge.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with bounding boxes saved as output_with_bounding_boxes_easyocr.png\n",
      "Horizontal Bounding Boxes: [(3069, 197, 222, 42), (1367, 271, 1631, 109), (1580, 359, 856, 110), (2004, 428, 676, 213), (3071, 487, 158, 150), (334, 589, 197, 52), (397, 652, 71, 48), (325, 699, 222, 61), (2418, 679, 434, 116), (364, 758, 144, 65), (2001, 829, 438, 110), (2707, 858, 516, 133), (931, 887, 604, 117), (1991, 917, 566, 110), (910, 1107, 394, 79), (1370, 1103, 386, 75), (1167, 1179, 147, 65), (1076, 1265, 238, 61), (1373, 1243, 769, 85), (1053, 1348, 269, 69), (953, 1453, 370, 79), (1375, 1450, 604, 69), (655, 1564, 211, 61), (859, 1553, 465, 92), (1378, 1555, 1401, 75), (1162, 1724, 1577, 75), (1161, 1791, 1383, 84), (737, 1893, 1776, 76), (2540, 1895, 806, 79), (694, 1956, 776, 75), (736, 2157, 2614, 84), (649, 2218, 2701, 85), (650, 2285, 2713, 81), (646, 2350, 1291, 75), (736, 2547, 2114, 87), (733, 2755, 2262, 79), (3016, 2760, 332, 65), (645, 2815, 2697, 88), (650, 2881, 532, 75), (733, 3018, 1165, 75), (736, 3216, 1957, 88), (737, 3423, 1361, 76), (732, 3559, 2606, 86), (736, 3624, 1088, 87), (737, 3907, 2593, 76), (651, 3971, 380, 65), (1059, 3964, 2277, 84), (649, 4029, 2691, 84), (646, 4094, 490, 77), (1238, 4097, 316, 69), (2799, 4098, 534, 69), (645, 4151, 2689, 85), (649, 4214, 2693, 87), (646, 4341, 2696, 78), (642, 4398, 2700, 86), (646, 4468, 2695, 81), (642, 4528, 2696, 85), (278, 4675, 970, 69), (1602, 4674, 1708, 73), (1596, 4744, 1507, 72), (1348, 4810, 225, 66), (1598, 4812, 1448, 75), (1365, 376, 218, 81), (2690, 443, 355, 239)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the EasyOCR reader with the desired language\n",
    "reader = easyocr.Reader(['fr'])  # Specify language\n",
    "\n",
    "# Load the image\n",
    "image_file = \"processed_image.png\"\n",
    "img = cv2.imread(image_file)\n",
    "\n",
    "# Detect text using EasyOCR\n",
    "results = reader.readtext(img)\n",
    "\n",
    "# Initialize a list to store the coordinates of horizontal bounding boxes\n",
    "bounding_boxes = []\n",
    "\n",
    "# Draw bounding boxes and store coordinates for each detected horizontal text region\n",
    "for (bbox, text, confidence) in results:\n",
    "    if confidence > 0.4:  # Confidence threshold\n",
    "        # bbox contains the coordinates of the box around the text\n",
    "        (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "        top_left = tuple(map(int, top_left))\n",
    "        bottom_right = tuple(map(int, bottom_right))\n",
    "\n",
    "        # Check if the bounding box is horizontal by comparing width and height\n",
    "        width = bottom_right[0] - top_left[0]\n",
    "        height = bottom_right[1] - top_left[1]\n",
    "        \n",
    "        if width > height:  # Only process if the width is greater than height\n",
    "            # Draw the rectangle around the horizontal text\n",
    "            img = cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)  # Green box\n",
    "            \n",
    "            # Append the bounding box to the list\n",
    "            bounding_boxes.append((top_left[0], top_left[1], width, height))\n",
    "\n",
    "# Save the initial image with bounding boxes\n",
    "output_image_path = \"output_with_bounding_boxes_easyocr.png\"\n",
    "cv2.imwrite(output_image_path, img)\n",
    "print(\"Image with bounding boxes saved as\", output_image_path)\n",
    "\n",
    "# Print bounding boxes for verification\n",
    "print(\"Horizontal Bounding Boxes:\", bounding_boxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
